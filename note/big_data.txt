------------------------------------------------elastic_search----------------------------------------------------------

    相关资料：
        入门：https://www.cnblogs.com/sunsky303/p/9438737.html
        官网：https://www.elastic.co

    1.概念
        es：有优于平时关系型数据库的查询性能，放弃一些新增/更新的性能
        -NRT
            接近实时的搜索
        -集群
            es从以开始就有集群的概念
        -节点
            es集群中的某服务器
        -索引
            类似与mysql的数据库
        -类型
            类似于mysql的表
        -文档
            类似于mysql的每条数据
        -分片
            将索引分成多份并能保存再不同的服务器上
            -可以水平分割/扩展内容容量
            -可以发布时并发的再分片上操作
        -复制
            熔灾备份
        -每个文档中的字段都可设置为索引，es中不建立索引就不能搜索
            -字段索引分类：
                -analyzed
                    -将分析字段，析分成多个关键词的搜索
                -not_analyzed
                    -不分析，整个字段为一个关键词
                -no
                    -非索引
    2.安装
        -先需要安装java
        -地址：https://www.elastic.co/cn/downloads/elasticsearch
        -修改配置的地址：&es/config/elasticsearch.yml

    3.原理
        -es使用倒排索引，为每个参数都会建立索引
        -倒排索引：
            将关键词提炼出来
            关键字与文档的对应关系保存
            再对关键字做索引排序
        -posting list 文档id
            posting-list需要增序保存
            -由FST压缩技术放在缓存
        -term dictionary 词典
            -关键字与posting-list的对应表
        -term index 词典索引
            -将词典的前缀提炼出来建立，将term-dictionary析分成块 前缀与词典的对应表
        -FST:
            每个id只保存他对应的长度的字节，并且保存的id是他离上个id的增量，如1，3保存1，2
            -bitmap:
                用0/1表示这个数存在不存在根据需要表示的数的增长长度线性增长，如:1,3,4保存为1011
            -roaring bitmaps:
                以65535为界限保存一个块的保存，用商/余数表示一组id
        -联合索引：
            -将查询出来的结果做 与 运算
        -原理总结:
            -es是尽力将磁盘的数据保存再内存上，先是term dictionary做出词典与文档id的对应关系表(即倒排索引)，考虑到冗余的int的保存方式，采用FST压缩了posting-list的空间
            最后将term-dictionary的前缀提出来做term-index与term-dictionary做对应表。
        -注意点：
            -1.针对不需要的用于查询的字段，要标注不需要索引，因为他会默认创建索引，索引过多的情况下，会减少插入/更新性能
            -2.对于string类型不需要用关键词索引的就不用analysis，不要随意浪费性能
            -3.id最好选择由规律的短id，随机性过高的id会影响查询性能
                原因：
                    -1.FST，保存数据是增量保存
                    -2.用文档id去磁盘找数据时，es磁盘是按segment分布

    4.API
        -整体交互都是rest风格的http请求
        -查看集群健康：
            GET "localhost:9200/_cat/heath?v"
        -查看集群节点信息
            GET "localhost:9200/_cat/nodes?v"
        -查看集群中的索引信息
            GET "localhost:9200/_cat/indices?v"
        -创建一个索引
            PUT "localhost:9200/index_test" -d '{"settings":{}}'
        -删除一个索引
            DELETE "localhost:9200/index_test"
        -创建一个索引的mapping
            PUT 'localhost:9200/index_test/_mapping/test_type' -d '{"test_type":{}}'
        -新增文档
            PUT 'localhost:9200/index_test/test_type/1' -d '{}'
        -更新文档
            POST 'localhost:9200/index_test/test_type/1' -d '{}'
        -删除文档
            DELETE 'localhost:9200/index_test/test_type/1'
        -GET 'localhost:9200/index_test/test_type/1?pretty'


-------------------------------------------------hbase----------------------------------------------------------------

    1.文档地址：https://www.w3cschool.cn/hbase_doc/hbase_doc-oge42vrm.html
    2.原理
        -客户端连接zk的地址就行，所有数据都先走zookeeper
        -HMaser管理所有的HRegionServer
        -1个HRegionServer有HLog和多个HRegion
            -HLog存操作日志（容灾）
            -HRegion存实际数据，分为MemoryStore和StoreFile
            -最终都存在 HDFS 里面
        -
    3.命令行API
        -列族 'info1:name'
        -$/bin/hbase shell 启动交互界面
        -list
            打印所有表
        -create 表名,列族名...
            创建表
        -alter 表名,{NAME=>'',VERSION=>''}
            修改表
        -drop 表名
            删除表(需要把表置为不可用才可删除)
        -put 表名 rowkey 列族 值
            新增（修改）数据
        -scan 表名 {过滤条件}
            查询数据
        -get 表名.rowkey {过滤条件}
            查询数据
        -delete 表名 rowkey 列族
            删除数据
    4.优化

-------------------------------------------------hdfs----------------------------------------------------------------
    1.优缺点：
        优点：
            1.存储非常大的文件
            2.采用流式的数据访问方式
            3.运行于商业硬件上  能运行在大部分机器上
        缺点：
            1.非低延时的数据访问
                HDFS是为高吞吐数据传输设计的,因此可能牺牲延时
            2.不适用大量小文件
                整个文件系统的文件数量会受限于NameNode的内存大小，如果文件过多导致文件目录也过多会占用大量内存
            3.不支持文件修改
                HDFS采用追加（append-only）的方式写入数据。不支持文件任意offset的修改。不支持多个写入器（writer）

    2.概念：
        1.Blocks
            -在物理Block的基础上再抽象了一层文件Block,默认为128M
            -一个大文件会被分解成block_size的多个Chunk单独存储
            -比128小的文件只占实际大小
            -Block大是为了减少定位到block的时间
            -以Block为单位可以分布在集群所有位置，不受单台服务器磁盘大小限制
            -以Block为副本单元，可以进行备份复制
        2.NameNode 和 DataNode
            -整个HDFS集群由NameNode和DataNode构成master-worker（主从）模式。
             NameNode负责构建命名空间，管理文件的元数据等，而DataNode负责实际存储数据，负责读写工作
            -NameNode
                -存放文件系统树及所有文件、目录的元数据
                    元数据持久化：namespace image和edit log
                -不持久化包括Block所在的节点列表，及文件的Block分布在集群中的哪些节点上，
                 这些信息是在系统重启的时候通过Datanode汇报的Block信息重新构建
                -HDFS针对单点故障提供了2种解决机制:
                    -备份持久化元数据
                        将文件系统的元数据同时写到多个文件系统， 例如同时将元数据写到本地文件系统及NFS。这些备份操作都是同步的、原子的。
                    -Secondary NameNode
                        其数据落后于Namenode，因此当Namenode完全崩溃时，会出现数据丢失
            -DataNode
                -数据节点负责存储和提取Block，读写请求可能来自namenode，也可能直接来自客户端
                -数据节点周期性向Namenode汇报自己节点上所存储的Block相关信息
        3.Block Caching
            -DataNode通常直接从磁盘读取数据，但是频繁使用的Block可以在内存中缓存,默认一个Block只有一个数据节点会缓存
            -用户或者应用可以向NameNode发送缓存指令（缓存哪个文件，缓存多久）， 缓存池的概念用于管理一组缓存的权限和资源
        4.HDFS Federation
            NameNode的集群
            每个NameNode管理一个namespace volumn,所有volumn构成文件系统的元数据
            每个NameNode同时维护一个Block Pool，保存Block的节点映射等信息
            每个NameNode相互独立
        5.HA 高可用
            -用secondaryNameNode在大型项目主节点失效切换时会耗用大量时间
            -采用HA的HDFS集群配置两个NameNode，分别处于Active和Standby状态。当Active NameNode故障之后，Standby接过责任继续提供服务
            -实现逻辑：
                1.主备需共享edit log存储
                    NFS：传统的网络文件系统
                    QJM：quorum journal manager一个多节点选举制的日志系统
                2.DataNode需要同时往主备发送Block Report
                    保证数据一致
                3.客户端需要配置failover模式
                    客户端配置有多个nameNode地址，不断尝试选择成功的地址。
