  
  1.redis介绍
	-nosql类型的数据库
	-性能非常高
	-分布式内存数据库,数据结构数据库
	
  2.redis核心
	-默认端口号:6379
	-核心组件:	解析指令,对数据做相应处理
	-然后将数据保存在内存中,类型有:string,hash,list,set集合,zset集合
		-hash 保存多对键值对的数据
		-list 前后可以加数据的channel(形容)
	-最后保存在文件里面:.dbf和.dbm
	
  3.基本操作
	-安装好后,默认有16个数据库,0-15
	1) string字符串
		-添加(修改)key-value(set)
			-set 键名 值
			
		-查看key-value
			-get 键名
		-删除指令:
			-del 键名
		-添加一个有时限的值,指定时间后删除
			-setex 键名 时间(秒) 值
		-一次性添加多个key-value
			-mset 键1 值1 键2 值2...
		-一次性获取多个Key-value
			-mget 键1 键2...
		-查看当前数据库有多少key-value
			-dbsize
		-DECR 键名			作用让键名对应的数字值-1
			-当键名不存在时,会让其值变成-1
			-无法对不是数字的值减,会报错
		-INCR 键名			作用让键名对应的数字值+1
			-当键名不存在时,会让其值先变成0 再+1
			-无法对不是数字的值减,会报错
		-EXISTS 键名		检查给定Key是否存在
			-存在1,不存在0
		-EXPIRE 键名 时间(s)	给指定键名生存时间,时间过后就会自动删除
			-设置成功返回1,失败0
		-EXPIREAT 键名 时间戳   在到达时间戳后自动删除
			-设置成功返回1,失败0
		-SETNX 创建一个key-value 设置成功返回1,失败0
			-区别于set setnx在key存在的时候不会修改value
			-作用于分布式锁
			-防止死锁:
				-set key value EX 时间 NX 设定时间后键过期,并且键存在不能对其操作
		-INCRBY 键名 数字	让键名增加值+上数字
			-同INCR相似,区别他可以设置增加的个数,而不是固定为1
			-无法对不是数字的值减,会报错
			-可以-->作用于分布式
		
	2) hash哈希
		-添加hash
			-hset 键名 字段名 值
		-查看hash某个键名某字段
			-hget 键名 字段名
		-查看hash某键的所有字段
			-hgetall 键名
		-删除hash
			-hdel 键名 字段名
		-添加hash(多个字段)
			-hmset 键名 字段1 值1 字段2 值2...
		-获取hash(多字段)
			-hmget 键名 字段1 字段2
		-查看hash有多少个字段
			-hlen 键名
		-增加hash表的某个字段的值
			-HINCRBY 键名 字段名 增加的数字
			-类似于set的incrby
		-删除一整个hash
			-del hash键名
		
		
	3) list列表
		-从左添加list
			-lpush 键名 值1 值2 值3 
		-从右添加List
			-rpush 键名 值1 值2 值3 
		-从左查看list
			-lrange 键名 开始索引 结束索引
			*取得时候顺序相反
		-从左删除一个数据	
			-lpop 键名
		-从右删除一个数据
			-rpop 键名
		-删除整个list列表
			-del 键名
		-返回当前整个list的长度,list不存在,返回0
			-LLEN 键名
		-弹出左一个元素,若没有元素,阻塞等待timeout秒
			-BLPOP key timeout
			-timeout = 0一直阻塞
		-弹出右一个元素,若没有元素,阻塞等待timeout秒
			-BRPOP key timeout
			-timeout = 0一直阻塞
			
	4) set集合
		-常用
			-添加set元素
				-sadd 键名 元素1 元素2...
			-查看set所有元素
				-smembers 键名
			-查看set是否有对应元素
				-sismembers 键名 元素名
				-返回1存在,返回0不存在 
			-删除Set指定元素
				-srem 键名 元素1 元素2...
				-成功返回1,不成功返回0
			-获取指定key元素个数
				-SCARD 键名
			-判断元素是否存在于key中
				-sismember 键名 元素名 
			-集合key中随机选count个元素
				-srandmember key [count]
			-集合key中随机选count个元素,同时这些元素从key中删除
				-spop key [count]
		-运算d
			-sinter key [key]	交集运算
			-sinterstore destination key [key] 交集运算结果放入destionation中
			-sunion key [key]	并集运算
			-sunionstore destination key [key] 并集运算结果放入destionation中
			-sdiff key [key]	差集运算
				-以第一个键为准,后面的键的值都会去掉与第一个键相同的值
			-sidffstore destination key [key] 差集运算结果放入destionation中
	
	5) zset有序集合
		-常用
			-添加zset元素
				-zadd 键名 分数名1 元素名1...
			-删除zset元素
				-zrem 键名 元素名...
			-返回zset中key的member的分数
				-zscore 键名 元素名
			-给zset中key的member分数+个分数
				-zincrby 键名 被加的分数 元素名
			-返回zset中key的个数
				-zcard key
			-正序获取有序集合start到stop的元素
				-zrange 键名 start stop [withscores]
			-逆序获取有序集合start到stop的元素
				-zrevrange 键名 start stop [withscores]
		-运算
			-zunionstore destkey 
	6) 通用
		-删除一整个键(任意类型)
			del 键名
		-查询一个键是否存在
			exists 键名
			
	-切换数据库 
		-select 库索引
	-清空当前数据库
		-flushdb
	-清空所有数据库
		-flushall
	-将内存的数据保存到文件上
		-SAVE			文件为:目录/dump.rdb
 
  4.String字符串-介绍
	-字符串最大value:512M
	-string类型:二进制,可以保存任何二进制
	-redis会对字符串转码保存
  
  5.hash哈希-介绍
	-一个键值对的集合,类似于golang的map类型
	-key值不能重复
	
 
  6.list列表-介绍	
	-list本质是一个链表,
	-list元素是有序的
	-元素的值可以重复
	-list数据都没有了对应的键消失

  7.set集合(无序)-介绍
	-元素是无序的
	-元素的值不能重复
	-添加时返回0,说明没有添加进去
	
  8.redis命令参考大全
	url:http://redisdoc.com/
	
  9.redi密码的设置:
	当没有密码的时候:
		config get requirepass XXX(password)	设置密码
	当有密码的时候:
		需要先验证密码:
			auth XXX
		再设置密码:	
			config get requirepass XXX(password)	设置密码
	登录有密码的redis:
		./src/redis-cli -p 6379 -a XXX
	
  10.事务
	事务开始:
		MULTI
	事务执行,并恢复连接状态:
		EXEC
	事务丢弃:；
		DISCARD
		
  11.keys
	keys *		查询所有键
	keys *XX*	查询指定键
	
  12.连接redis服务器
	redis-cli -h 地址
	
  13.redis数据结构底层
    参考文档:https://blog.csdn.net/zwx900102/article/details/109543659
    -基本组成
        -字符串
            -对c字符串进行了重新定义
            -使用:sds作为数据结构
            -sds:
                -保证二进制安全:去掉C字符串需要的\0结尾字符
                -保存length,读取长度复杂度为1
                -预分配容量,不会出现缓冲区溢出情况,减少内存分配次数
        -dictEntry
            -顶层obj
            -键:sds 值:redisObj
            -同时为了防止hash冲突有拉链表
        -redisObj
            -保存数据信息的数据结构
            -保存的信息有:
                -type对象类型
                -encoding编码
                -lru最后一次被访问时间
                -refcount被引用次数
                -ptr实际的数据存储结构
            -3编码类型
                -int
                    当我们用字符串对象存储的是整型,且能用8个字节的long类型进行表示(即263-1)
                    则Redis会选择使用int编码来存储,而且此时redisObject对象中的ptr指针直接替换为long类型
                -embstr
                    当字符串对象中存储的是字符串,且长度小于44(3.2版本之前是39)时,Redis会选择使用embstr编码来存储
                -sds
                    当字符串对象中存储的是字符串,且长度大于44时,Redis会选择使用raw编码来存储
                -编码一旦升级,不会回退
    -list
        -使用:linked-list+zip-list(老),quick-list(新)
        -linked-list
            -双向列表
        -zip-list
            -压缩类型的列表,使用连续内存块的顺序结构
            -目的:时间换空间,压缩内存利用率
            -保存上一个节点的长度和当前节点的长度,然后依次推理出上下节点的位置
            -组成:
                -zlbytes
                    -记录压缩列表占用内存字节数(包括本身所占用的4个字节)
                -zltail
                    -记录压缩列表尾节点距离压缩列表的起始地址有多少个字节(通过这个值可以计算出尾节点的地址)
                -zllen
                    -记录压缩列表中包含的节点数量,当列表值超过可以存储的最大值(65535)时,次值固定存储65535,因此此时需要遍历整个压缩列表才能计算出真实节点数
                -zlentry
                    -压缩列表中的各个节点,长度由存储的实际数据决定
                    -prevlen
                        -存储了前一个entry的长度
                        -当链表的前一个entry占用字节数小于254,此时prevlen只用1个字节进行表示.
                        -当链表的前一个entry占用字节数大于等于254,此时prevlen用5个字节来表示,
                         其中第1个字节的值是254(相当于是一个标记,代表后面跟了一个更大的值),后面4个字节才是真正存储前一个entry的占用字节数
                    -encoding
                        -存储了当前entry所保存数据的类型以及长度
                        -可以直接存储0-12小整数 11110001 - 11111101 ((1-13) - 1)
                    -entry-data
                        -具体的数据
                        -小整数不用存
                -zlend
                    -特殊字符0xFF(十进制255),用来标记压缩列表的末端(其他正常的节点没有被标记为255的,因为255用来标识末尾,后面可以看到,正常节点都是标记为254)
        -quick-list
            -linked-list和zip-list的结合,双向列表+列表内是个zip-list
            -数据结构
                -quicklist
                    typedef struct quicklist {
                        quicklistNode *head;//列表头节点
                        quicklistNode *tail;//列表尾节点
                        unsigned long count;//ziplist中一共存储了多少元素,即:每一个quicklistNode内的count相加
                        unsigned long len; //双向链表的长度,即quicklistNode的数量
                        int fill : 16;//填充因子
                        unsigned int compress : 16;//压缩深度 0-不压缩
                    } quicklist;
                -quicklistNode
                    typedef struct quicklistNode {
                        struct quicklistNode *prev;//前一个节点
                        struct quicklistNode *next;//后一个节点
                        unsigned char *zl;//当前指向的ziplist或者quicklistLZF
                        unsigned int sz;//当前ziplist占用字节
                        unsigned int count : 16;//ziplist中存储的元素个数,16字节(最大65535个)
                        unsigned int encoding : 2; //是否采用了LZF压缩算法压缩节点 1:RAW 2:LZF
                        unsigned int container : 2; //存储结构,NONE=1, ZIPLIST=2
                        unsigned int recompress : 1; //当前ziplist是否需要再次压缩(如果前面被解压过则为true,表示需要再次被压缩)
                        unsigned int attempted_compress : 1;//测试用
                        unsigned int extra : 10; //后期留用
                    } quicklistNode;
                -compress 压缩深度 0-不压缩
                    -首尾X元素不压缩
                    -设计原因:很多场景都是两端的元素访问率较高,而中间元素访问率相对较低
                    -可以通过参数 list-compress-depth 控制
                -zl
                    -zl指针默认指向了ziplist,sz属性记录了当前ziplist占用的字节
                    -不过这仅仅限于当前节点没有被压缩(LZF压缩算法)的情况,如果当前节点被压缩了,那么zl指针会指向另一个对象quicklistLZF,quicklistLZF是一个4+N字节的结构
                    -可以通过参数 list-max-ziplist-size 控制entry大小
                        -可以为正数与负数,0无限制 -1到-5:(4,8,16,32,64kb)
    -hash
        -使用:zip-list + hashtable
        -数据少时用zip-list,数据多时用hashtable
        -hashtable
            -原型:
                typedef struct dict {
                    dictType *type;//字典类型的一些特定函数
                    void *privdata;//私有数据,type中的特定函数可能需要用到
                    dictht ht[2];//哈希表(注意这里有2个哈希表)
                    long rehashidx; //rehash索引,不在rehash时,值为-1
                    unsigned long iterators; //正在使用的迭代器数量
                } dict;

                typedef struct dictht {
                    dictEntry **table;//哈希表数组
                    unsigned long size;//哈希表大小
                    unsigned long sizemask;//掩码大小,用于计算索引值,总是等于size-1
                    unsigned long used;//哈希表中的已有节点数
                } dictht;
            -ht
                -两个哈希表存数据
                -而Redis在默认情况下使用的是ht[0],不会为ht[1]初始化分配空间
                -rehash时使用第二个hash:
                    -rehash条件:
                        -1.负载因子大于等于1且dict_can_resize设置为1时
                        -2.负载因子大于等于安全阈值(dict_force_resize_ratio=5)时
                        -负载因子=哈希表已使用节点数/哈希表大小(即:h[0].used/h[0].size)
                    -rehash步骤
                        -1.为字典dict的ht[1]哈希表分配空间,其大小取决于当前哈希表已保存节点数(即:ht[0].used).
                         (a).扩展操作则ht[1]的大小为2n中第一个大于等于ht[0].used * 2属性的值(比如used=3,此时23就是第一个大于used * 2 的值(22<6且23>6)).
                         (b).收缩操作则ht[1]大小为2n中第一个大于等于ht[0].used的值.
                        -2.将字典中的属性rehashix的值设置为0,表示正在执行rehash操作.
                        -3.将ht[0]中所有的键值对依次重新计算哈希值,并放到ht[1]数组对应位置,完成一个键值对的rehash之后rehashix的值需要加1.
                        -4.当ht[0]中所有的键值对都迁移到ht[1]之后,释放ht[0],并将ht[1]修改为ht[0],然后再创建一个新的ht[1]数组,为下一次rehash做准备.
                        -5.将字典中的属性rehashix设置为-1,表示rehash已经结束
                    -渐进式rehash
                        上面介绍的这种方式因为不是一次性全部rehash,而是分多次来慢慢的将ht[0]中的键值对rehash到ht[1]的操作就称之为渐进式rehash.
                        渐进式rehash可以避免了集中式rehash带来的庞大计算量,采用了分而治之的思想.
                        在渐进式rehash过程中,因为还可能会有新的键值对存进来,此时Redis的做法是新添加的键值对统一放入ht[1]中,这样就确保了ht[0]键值对的数量只会减少.
                        当执行rehash操作时需要执行查询操作,此时会先查询ht[0],查找不到结果再到ht[1]中查询.
        -ziplist和hashtable的编码转换
            -当一个哈希对象可以满足以下两个条件中的任意一个,哈希对象会选择使用ziplist编码来进行存储:
                1.哈希对象中的所有键值对总长度(包括键和值)小于64字节(这个阈值可以通过参数hash-max-ziplist-value 来进行控制).
                2.哈希对象中的键值对数量小于512个(这个阈值可以通过参数hash-max-ziplist-entries 来进行控制).
                一旦不满足这两个条件中的任意一个,哈希对象就会选择使用hashtable来存储.
    -set
        -集合使用intset+hashtable
        -intset
            intset(整数集合)可以保存类型为int16_t,int32_t,int64_t的整数值,并且保证集合中没有重复元素.
            -原型:
                typedef struct intset {
                    uint32_t encoding;//编码方式
                    uint32_t length;//当前集合中的元素数量
                    int8_t contents[];//集合中具体的元素
                } intset;
            -encoding
                encoding记录了当前集合的编码方式,主要有三种:
                -INTSET_ENC_INT16
                 此时contents[]内的每个元素都是一个int16_t类型的整数值,范围是:-32768 ~ 32767(-215 ~ 215-1)
                -INTSET_ENC_INT32
                 此时contents[]内的每个元素都是一个int32_t类型的整数值,范围是:-2147483648 ~ 2147483647(-231 ~ 231-1)
                -INTSET_ENC_INT64
                 此时contents[]内的每个元素都是一个int64_t类型的整数值,范围是:-9223372036854775808 ~ 9223372036854775807(-263 ~ 263-1)
            -contents[]
                contents[]虽然结构的定义上写的是int8_t类型,但是实际存储类型是由上面的encoding来决定的
            -整数集合的升级
                -假如一开始整数集合中的元素都是16位的,采用了int16_t类型来存储,此时需要再存储一个32位的整数,那么就需要对原先的整数集合进行升级,升级之后才能将32位的整数放入整数集合内.
                -升级主要有4个步骤:
                    1.根据新添加元素的类型来扩展底层数组空间的大小,按照升级后现有元素的位数来分配新的空间.
                    2.将现有的元素进行类型转换,并将转换类型后的元素从后到前逐个重新放回到数组内.
                    3.将新元素放到数组的头部或者尾部（因为触发升级的条件就是当前数组的整数类型无法存储新元素,所以新元素要么比现有元素都大,要么就比现有元素都小）.
                    4.将encoding属性修改为最新的编码,并且同步修改length属性.
    -zset
        -有序集合用链表实现
        -使用:skip_list跳表做索引
        -skip_list:
            -两个连续的链表有个上级链表父节点
             两个连续的链表父节点又有个上级链表父节点
	         ...
            -查询的时候跳着找,有二分思想
            -复杂度: log(n)

  14.redis事务
    -命令:
        -multi:开启事务
        -exec:执行事务
        -discard:取消事务
        -watch:监视
            监视事务中的key,如果key被修改,事务所有命令不被执行
    -特点:
        -原子性Atomicity:
            无原子无回滚
            如果我们开启事务之后,命令在进入队列之间就报错了,那么事务将会被取消,
            而一旦命令成功进入队列之后,单个命令的报错就不会影响其他命令的执行,也就是说Redis中的事务并不会回滚
        -一致性Consistency
            一致性指的就是事务执行前后的数据符合数据库的定义和要求。
            这一点Redis是符合要求的,上面讲述原子性的时候已经提到,不论是发生语法错误还是运行时错误,错误的命令均不会被执行。
        -隔离性Isolation
            事务中的所有命令都会按顺序执行,在执行Redis事务的过程中,另一个客户端发出的请求不可能被服务,
            这保证了命令是作为单独的独立操作执行的。所以Redis当中的事务是符合隔离性要求的。
        -持久性Durability
	        内存操作无持久性

  15.内存回收
    -过期策略
        -设置了过期的key,到了时间被删除的策略
        1、定时删除:
            为每个键设置一个定时器,一旦过期时间到了,则将键删除。这种策略对内存很友好,但是对CPU不友好。因为每个定时器都会占用一定的CPU资源。
        2、惰性删除:
            不管键有没有过期都不主动删除,等到每次去获取键时再判断是否过期,如果过期就删除该键,否则返回键对应的值。这种策略对内存不够友好,可能会浪费很多内存。
        3、定期扫描:
            系统每隔一段时间就定期扫描一次,发现过期的键就进行删除。这种策略相对来说是上面两种策略的折衷方案,但是这个定期的频率需要结合实际情况掌控好,但是这种方案也可能会出现过期的键也被返回。
        -redis采用 惰性删除 + 定期扫描
    -淘汰策略
        -redis参数maxmemory可以设置redis最大使用内存,不设置时32位最多使用3G内存
	    -redis中提供了8种淘汰策略,通过参数maxmemory-policy进行配置:
	        -volatile-lru
	            根据LRU算法删除设置了过期时间的键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -allkeys-lru
                根据LRU算法删除所有的键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -volatile-lfu
                根据LFU算法删除设置了过期时间的键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -allkeys-lfu
                根据LFU算法删除所有的键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -volatile-random
                随机删除设置了过期时间的键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -allkeys-random
                随机删除所有键,直到腾出可用空间。如果没有可删除的键对象,且内存还是不够用时,则报错
            -volatile-ttl
                根据键值对象的ttl属性, 删除最近将要过期数据。 如果没有,则直接报错
            -noeviction
                默认策略,不作任何处理,直接报错
        -redis的LRU
             为避免传统LRU的问题:需要额外的空间进行存储,可能存在某些key值使用很频繁,但是最近没被使用,从而被LRU算法删除
             redis采用随机抽取X个数量的key,再LRU删除空闲最长的
             X数量根据maxmemory_samples来判断,默认为5
            -新版redis又加了缓冲池:
                当每一轮移除Key时,拿到了这个N个Key的idle time,如果它的idle time比 pool 里面的 Key的idle time还要大,就把它添加到pool里面去,再删除pool里面最大的
	    -redis的LFU
	        -LFU:
	            Least Frequently Used,即:最近最少频率使用,这个主要针对的是使用频率。
	            高16位用来记录访问时间,低8位用来记录访问频率,8位因此最大访问数位255
            -访问频次递增:
                -lfu_log_factor对数因子,为参数控制
                -算法:
                    1、提取0和1之间的随机数R
                    2、概率P计算为1/(old_value*lfu_log_factor+1)。
                    3、当R<P时,频次进行递增
            -访问频次的减少:
                -lfu-decay-time参数: 单位为分钟。
                    N分钟内没有访问,counter就要减N
	            -算法:
	                1、获取当前时间戳,转化为分钟后取低16位（为了方便后续计算,这个值记为now）。
                    2、取出对象内的lru属性中的高16位（为了方便后续计算,这个值记为ldt）。
                    3、当lru>now时,默认为过了一个周期(16位,最大65535),则取差值65535-ldt+now；当lru <=now时,取差值now-ldt（为了方便后续计算,这个差值记为idle_time）。
                    4、取出配置文件中的lfu_decay_time值,然后计算:idle_time / lfu_decay_time（为了方便后续计算,这个值记为num_periods）。
                    5、最后将counter减少:counter - num_periods

  16.redis的持久化
    -两种持久机制:RDB+AOF
    -RDB:
        -概念:
            Redis DataBase,是Redis当中默认的持久化方案,当触发持久化条件时,
            Redis会生成一个dump.rdb文件,Redis在重启的时候就会通过解析dump.rdb文件进行数据恢复。
	    -触发条件:
	        -自动触发
	            1、执行flushall命令(flushdb命令不会触发)时,不过此时生成的读,dump文件内的数据是空的
	            （dump文件还会存储一些头信息,所以文件本身是有内容的,只是没有数据）,没有什么太大的意义。
	            2、执行shutdown命令时会触发生成dump文件。
	            3、通过配置文件自动生成,Redis中配置文件默认配置如下:
	        -手动触发
	            save命令:这个命令会阻塞Redis服务器进程,直到成功创建RDB文件,也就是说在生成RDB文件之前,服务器不能处理客户端发送的任何命令。
	            bgsave命令:父进程会执行fork操作来创建一个子进程。RDB文件由子进程来负责生成,父进程可以正常处理客户端发送的命令
        -RDB机制优点
            1、RDB是一个非常紧凑的压缩文件,保存了不同时间点上的文件,非常适合用来灾备和数据恢复。
            2、RDB最大限度地提高了Redis的性能,因为Redis父进程需要做的唯一的工作就是派生一个子进程来完成剩下的工作。父进程永远不会执行磁盘I/O或类似的操作。
            3、与AOF机制想必,RDB方式恢复数据的速度更快
        -RDB机制相关配置文件
            dir:rdb文件生成目录。默认是./(当前目录),可以执行命令:config get dir进行查看
            dbfilename:rdb文件名。默认是dump.rdb
            rdbcompression:rdb文件是否是LZF压缩文件。默认是yes
            rdbchecksum:是否开启数据校验。默认是yes
        -RDB机制缺点
	        1、RDB无法做到实时备份,所以如果Redis停止工作而没有正确的关机,那么从上一次备份的到异常宕机的这一段时间的数据将会丢失。
            2、RDB通常需要父进程来执行fork()操作创建子线程,所以如果频繁执行fork()的而CPU性能又不是很高的话可能会造成短时间内父进程不可用。
	-AOF
	    -概念:
            Append Only File,是Redis当中提供的另一种持久化机制。AOF采用日志的形式将每个写操作追加到文件中。
            开启AOF机制后,只要执行更改Redis数据的命令时,命令就会被写入到AOF文件中。
            在Redis重启的时候会根据日志内容执行一次AOF文件中的命令来恢复数据。
	    -与RDB的不同
	        AOF和RDB最大的不同时AOF记录的是执行命令（类似于MySQL中binlog的statement格式）,而RDB记录的是数据（类似于MySQL中binlog的row格式）。
        -开启AOF
            appendonly 修改为yes
            当与RDB并存时,使用AOF
	    -控制实时写入appendfsync参数:
	        always 慢
	            写入缓存的同时通知操作系统刷新(fsync)到磁盘(但是也可能会有部分操作系统只是尽快刷盘,而不是实时刷盘)
            everysec 中
                先写入缓存,然后每秒中刷一次盘(默认值),这种模式极端情况可能会丢失1s的数据
            no 快
                只写入缓存,什么时候刷盘由操作系统自己决定
        -AOF重写
            -概念:
                AOF机制主要是通过记录执行命令的方式来实现的,那么随着时间的增加,AOF文件不可避免的会越来越大,而且可能会出现很多冗余命令。
                比如同一个key值执行了10000次set操作,实际上前面9999次对用户来说都是没用的,用户只需要最后一次执行命令,所以AOF机制就提供了重写功能。
            -原理:
                AOF重写时Redis并不会去分析原有的文件,因为如果原有文件过大,分析也会很耗时,所以Redi选择的做法就是重新去Redis中读取现有的键值,然后用一条命令记录键值对的值
	            如果在AOF重写的时候,如果一个集合键或者列表键或者哈希键内包含的元素超过64个,那么也会采用多条命令来进行重写
	            #define AOF_REWRITE_ITEMS_PER_CMD 64
	        -实现:
	            如果在AOF重写的时候,如果一个集合键或者列表键或者哈希键内包含的元素超过64个,那么也会采用多条命令来进行重写。
	            一致性:为了解决数据不一致问题,Redis中引入了一个AOF重写缓冲区。当开始执行AOF重写之后接收到的命令,不但要写入原本的AOF缓冲区(根据上面提到的参数刷盘),还要同时写入AOF重写缓冲区:
                一旦子进程完成了AOF文件的重写,此时会向父进程发出信号,父进程收到信号之后会进行阻塞（阻塞期间不执行任何命令）,并进行以下两项工作:
                    1、将AOF重写缓冲区的文件刷新到新的AOF文件内
                    2、将新AOF文件进行改名并原子的替换掉旧的AOF文件
                完成了上面的两项工作之后,整个AOF重写工作完成,父进程开始正常接收命令。
        -触发条件
            -自动参数:
                auto-aof-rewrite-percentag //文件大小超过上次AOF重写之后的文件的百分比。默认100,也就是默认达到上一次AOF重写文件的2倍之后会再次触发AOF重写
                auto-aof-rewrite-min-size //设置允许重写的最小AOF文件大小,默认是64M。主要是避免满足了上面的百分比,但是文件还是很小的情况。
            -手动命令:
	            bgrewriteaof命令
	    AOF机制机制优点
            1、使用AOF机制，可以自由选择不同fsync(刷盘)策略，而且在默认策略下最多也仅仅是损失1s的数据
            2、AOF日志是一个仅追加的日志，因此如果出现断电，也不存在查找或损坏问题。即使由于某些原因(磁盘已满或其他原因)，日志以写了一半的命令结束，redis-check-aof工具也能够轻松地修复它。
            3、当AOF变得太大时，Redis能够在后台自动重写。
            4、不通过与RDB的文件格式，AOF是一种易于理解和解析的格式，依次包含所有操作的日志。
        AOF机制机制缺点
            1、对于相同的数据集，AOF文件通常比等效的RDB文件大。
            2、根据fsync的具体策略，AOF可能比RDB慢。但是一般情况下，fsync设置为每秒的性能仍然很高，禁用fsync后，即使在高负载下，它的速度也应该和RDB一样快。
            3、因为AOF文件是追加形式，可能会遇到BRPOP、LPUSH等阻塞命令的错误，从而导致生成的AOF在重新加载时不能复制完全相同的数据集，而RDB文件每次都是重新从头创建快照，这在一定程度上来说RDB文件更加健壮。

  17.redis发布订阅
    -命令:
        subscribe 订阅频道
        uncubscribe 取消频道的订阅
        publish 向频道发送消息
	    punsub 查看当前服务器被订阅的频道
	    pubsub 查看指定频道的订阅数
    -结构:
        struct redisServer {
        	dict *pubsub_channels;//保存了客户端及其订阅的频道信息
        	//...
        };
	    pubsub_channels属性是一个字典，其key值保存的就是频道名，value是一个链表，链表中保存的就是客户端id
    -原理:
        -订阅
            订阅的时候首先会检查字典内是否存在这个频道:如果不存在，则需要为当前频道创建一个字典，同时创建一个链表作为value，并将当前客户端id放入链表；如果存在，则直接将当前客户端id放入链表即可。
        -取消订阅
            取消订阅的时候需要将客户端id从对应的链表中移除，如果移除之后链表为空，则需要同时将该频道从字典内删除。
        -发送消息
            发送消息时首先会去pubsub_channels字典内寻找键，如果发现有可以匹配上的键，则会找到对应的链表，进行遍历发送消息。

  18.redis支持lua脚本
    -目的:
        使用Lua脚本最大的好处是Redis会将整个脚本作为一个整体执行，不会被其他请求打断，可以保持原子性且减少了网络开销
    -lua语法:
        eval lua-script numkeys key [key ...] arg [arg ...]
        -eval:执行Lua脚本的命令
        -lua-script:lua脚本内容
        -numkeys:表示的是Lua脚本中需要用到多少个key，如果没用到则写0
        -key [key …]:将key作为参数按顺序传递到Lua脚本，numkeys是0则可省略
        -arg:Lua脚本中用到的参数，如果没有可省略
	-Lua脚本中执行Redis命令:
	        redis.call(command, key [key ...] argv [argv…])
        -例子:
            eval "return redis.call('set',KEYS[1] , ARGV[1])" 1 name ltt
        -ps:
            KEYS和ARGV必须要大写，参数的下标从1开始,KEYS和ARGV点之间的空格不能省略
    -lua脚本摘要（脚本缓存）
        lua脚本会自动生成摘要,方便减少下次运行的调用的花销(LUA脚本的网络传输)
    -命令:
        script load: 手动生成LUA脚本摘要
        evalsha: 只要执行lua脚本
        script exists: 判断一个摘要是否存在
        script flush: 清除所有Lua脚本缓存。
	    script kill: 强制终止当前lua脚本的执行
	        ps:该命令单进程能执行原理:LUA允许hook函数
    -参数：
        lua-time-limit 控制Lua脚本执行的超时时间，默认是5000ms

  19.redis集群
    参考：https://blog.csdn.net/zwx900102/article/details/110495732
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	